# Notes 11.12.2019

Einzeltreffen mit Marco. Haben Prototypen als WebApp präsentiert.

## Remarks
- 3 Hauptpunkte momentan (Funktionalität + User-friendliness)
    - Kalibrierung
    - Notification
    - UI
- Weitere Möglichkeiten:
    - Face-Detection (--> robustness)
- Calibration Data: wie wird sie genutzt?
- Wie wird Körperdrehung erkannt? Kann es durch "verdächtig" kurzen Vektor erkannt werden?
- Ydifference, um "Heruntersacken" und schiefen Rücken zu erkennen
- Face Detection mit js-API: bei Kalibrierung Gesicht erkennen und abspeichern
- Timer (funktionieren schon):
    - Gesamtzeit
    - Sitzzeit
    - [Pause time = Differenz aus Gesamtzeit und Sitzzeit => für Pausenempfehlungen nutzbar]
    - Bad time
    - Good time
- Feedback einholen zu Ressourcen sparen
- Noch andere Ideen/Ansätze außer Mean über Zeit? 
    -  => evtl. Median anstatt Mean
- Feedback regelbasiertes Verfahren?
- Kamera trotzdem anzeigen
- Weitere Optionen:
  - siehe oben: evtl. mal Median anstatt Mean ausprobieren
  - Wieviel Bewegung gab es in einem bestimmten Zeitraum?
  - Weitere Zustände: z.B. schaut auf Bildschirm/schaut weg (wieviel %)
  - Abgleich Gesichts-Trackingpunkte mit Face-Detection => Face Detection muss nicht durchgehend laufen, sondern nur alle x Sekunden, zwischendrin Abgleich mit Gesichts-Trackingpunkten => immer noch in Nähe des erkannten Gesichts? Dann noch vorm Bildschirm.
  - Allgemein: was kann man aus dem bisher verfügbaren Output noch machen, um an Informationen über den Zustand des Users vorm PC zu kommen


## Dates
- Nächste Woche (18.12.): Präsentation
    - Kernidee, Hauptfeatures
    - Motivation (Pitch)
    - Was sind die Komponenten?
    - Live Demo
    - Schwierigkeiten / Lessons learned => Gefühl vermitteln, wie gut/robust läuft es, etc…